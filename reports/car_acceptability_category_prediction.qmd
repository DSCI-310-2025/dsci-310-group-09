---
title: "Car Acceptability Category Prediction Analysis"
author: "Jiaming Change, Yicheng Huang, Effie Wang, & Brianna Zhou"
format: 
  html:
    number-figures: true
    number-tables: true
    embed-resources: true
editor: source
bibliography: references.bib
toc: true
execute:
   echo: false
   warning: false
---

## Summary

We aim to develop a Random Forest classification model to predict car acceptability categories: unacceptable (unacc), acceptable (acc), good (good), and very good (vgood). This prediction is based on categorical attributes such as price, maintenance cost, safety, and seating capacity. The data is sourced from the Car Evaluation dataset found in the UCI Machine Learning Repository [@Bohanec1988].

During the initial data exploration, we discovered a significant class imbalance, with the majority of instances labeled as "unacceptable." To address this issue and improve the model’s ability to recognize minority classes, we applied ordinal encoding to the categorical features and used SMOTE (Synthetic Minority Over-sampling Technique) to balance the class distribution.

Following these preprocessing steps, we trained a Random Forest classifier and evaluated its performance on a test set. The model achieved an accuracy closed t0 99% accuracy and a Kappa statistic near 0.99 on the test data after SMOTE was applied during training, indicating strong predictive power and a high level of agreement between predicted and actual labels.

In summary, this analysis demonstrates how machine learning can be effectively applied to real-world decision-making in the automotive sector.

## Introduction

Evaluating car acceptability is a critical factor in decision-making within the automotive industry. It affects consumer choices regarding vehicle purchases, manufacturers' priorities, and dealership strategies. Car purchases represent one of the most significant financial decisions for households, with affordability being the primary barrier for many buyers. Price plays a crucial role in accessibility, particularly for budget-conscious consumers, such as first-time buyers or individuals in emerging markets.

According to @Chiu2022, price dispersion positively impacts car acceptability. Because car purchases are high-cost, long-term investments, misaligned choices due to information asymmetry—such as undervaluing safety features—can lead to serious financial or safety repercussions [@Canada2024]. For instance, vehicles with poor safety ratings have been linked to higher accident rates. Consequently, @Vrkljan2011 concluded that safety is considered the most important feature when purchasing a vehicle. Automating car evaluations helps buyers efficiently identify optimal vehicles, aligning with the trend toward data-driven consumer tools. Recognizing critical features, such as safety and price, reflects the industry's priorities in vehicle design.

This project aims to develop a classification model to predict car acceptability based on various features such as price, maintenance cost, safety, and seating capacity. This analysis uses the [Car Evaluation dataset](https://archive.ics.uci.edu/dataset/19/car+evaluation), which contains 1,728 instances and six features: buying price, maintenance cost, number of doors, seating capacity, luggage size, and safety rating. With an increasing number of car models available in the market, understanding how different attributes affect car classification can help streamline the evaluation process. The goal is to predict car acceptability categories: unacceptable (unacc), acceptable (acc), good (good), and very good (vgood). Being able to predict car acceptability can enhance automated recommendations, improve quality control, and support consumer purchasing decisions.

## Method & Results

```{r}
#library(tidyverse)
library(knitr)
```

### Importing Data & Data Exploration

Reads the dataset, assigns appropriate and meaningful column names, checks the number of rows, and convert all categorical variables into factors. The dataset consists of 1,728 rows with 6 categorical features related to car evaluation. 

```{r}
#| label: tbl-cleaned_data
#| tbl-cap: Cleaned Data
cleaned_data <- readRDS("../data/cleaned/cleaned.RDS")
knitr::kable(head(cleaned_data,5))

```

### Summary and Missing Data Check

Provides a summary of each feature, including frequency distributions and potential missing values. It also checks for class imbalance in the target variable `class`. There is no missing value in attributes.
```{r}
summary(cleaned_data)
```

### Class Distribution Visualization

Generates a bar chart showing how the car evaluations are distributed across different categories. This helps identify class imbalances.

```{r}
#| label: tbl-frequency_distri_car  
#| tbl-cap: Frequency distribution of the Car Acceptability Category.

freq_table <- readRDS("../output/tbl_target_dist.RDS")
knitr::kable(freq_table, col.names = c("class", "Frequency"))

```


![Distribution of Car Evaluations](../output/fig_target_dist.png){#fig-car_distribution_plot width="60%"}

The dataset shows significant class imbalance as shown in @tbl-frequency_distri_car and @fig-car_distribution_plot, with the `unacc` (unacceptable) class dominating at 71% of the original data (1,210 out of 1,728 instances). This imbalance may skew model predictions, leading to poor performance on the minority classes (`good`, `vgood`).

### Feature Relationships Visualization

Creates bar charts for each feature to analyze its relationship with the target variable `class`. This helps identify important factors influencing car evaluations.


![Safety vs. Evaluation Class](../output/fig_relation_safety_1.png){#fig-car_safety_plot width="60%"}

![Buying vs. Evaluation Class](../output/fig_relation_buying_1.png){#fig-car_buying_plot width="60%"}

![Number of Passenger vs. Evaluation Class](../output/fig_relation_persons_1.png){#fig-car_persons_plot width="60%"}

![Maintenance vs. Evaluation Class](../output/fig_relation_maint_1.png){#fig-car_maintenance_plot width="60%"}

![Luggage Boot Size vs. Evaluation Class](../output/fig_relation_lug_boot_1.png){#fig-car_luggage_plot width="60%"}

![Number of Doors vs. Evaluation Class](../output/fig_relation_doors_1.png){#fig-car_doors_plot width="60%"}


The analysis of various features—such as safety @fig-car_safety_plot, buying price @fig-car_buying_plot, passenger capacity @fig-car_persons_plot, maintenance cost @fig-car_maintenance_plot, luggage boot size @fig-car_luggage_plot, and number of doors—shows @fig-car_doors_plot that the dominant classification is `unacc` (unacceptable), which indicates a pattern of negative evaluations.

There is a strong correlation between high safety ratings and the classifications `vgood` (very good) and "good". In contrast, vehicles that have low to medium safety ratings, along with high buying and maintenance costs, are often classified as `unacc`.

Affordable cars, particularly those with low to medium prices, and vehicles with larger luggage boot sizes tend to have higher proportions of `acc` (acceptable) or `vgood` ratings. Conversely, cars with larger passenger capacities or smaller boots are frequently labeled as `unacc`.

The number of doors appears to have a minimal impact on the evaluations, as `unacc` remains the most common classification regardless of this feature.

### Feature Engineering and Data Resampling

To prepare the categorical features for model training, we applied ordinal encoding to convert string-based categorical variables into meaningful numeric representations. This transformation is necessary for the Random Forest classifier, which requires numerical input. @tbl-encoded_variable shows an example of the encoded data.

```{r}
#| label: tbl-encoded_variable
#| tbl-cap: Ordinal Encoding of Categorical Variables.

encoded_variable_table <- readRDS("../output/encoded.RDS")
knitr::kable(head(encoded_variable_table, 5))
```

### Handling Class Imbalance Using SMOTE

During the initial data exploration, a significant issue identified was the severe class imbalance in the dataset. The majority class, "unacceptable" (`unacc`), comprised 1,210 out of 1,728 instances, significantly outnumbering the other categories: "acceptable" (`acc`) with 384 instances, "good" (`good`) with 69 instances, and "very good" (`vgood`) with just 65 instances. This imbalance posed a serious risk of bias in model training. A classifier could achieve high overall accuracy by predominantly predicting the majority class, which would result in poor performance on the minority classes.

To address this, we applied SMOTE (Synthetic Minority Over-sampling Technique), which generates synthetic examples for underrepresented classes by interpolating between existing minority samples. This technique not only increased the number of minority class instances but also introduced greater variability within them, helping the model learn more robust decision boundaries.

![Distribution of Car Evaluations After Feature Engineering](../output/fig_smote_dist.png){#fig-car_distri_after_enginerring_plot width="60%"}

After applying SMOTE, the class distribution became approximately balanced, with each class containing around 1,250 instances, as shown in @fig-car_distri_after_enginerring_plot. This transformation enabled the model to give equal importance to each category during training, which significantly improved its ability to accurately classify "good" and "very good" cars—categories that might have otherwise been overlooked. The enhanced performance metrics for each class further demonstrate that SMOTE effectively reduced bias and improved the model’s predictive fairness across all categories.

### Visualizing relationships with Class Balanced

![Safety vs. Evaluation Class with Class Balance](../output/fig_relation_safety_2.png){#fig-car_safety_balance_plot width="60%"}

![Buying vs. Evaluation Class with Class Balance](../output/fig_relation_buying_2.png){#fig-car_buying_balance_plot width="60%"}

![Number of Passenger vs. Evaluation Class with Class Balance](../output/fig_relation_persons_2.png){#fig-car_persons_balance_plot width="60%"}

![Maintenance vs. Evaluation Class with Class Balance](../output/fig_relation_maint_2.png){#fig-car_maintenance_balance_plot width="60%"}

![Luggage Boot Size vs. Evaluation Class with Class Balance](../output/fig_relation_lug_boot_2.png){#fig-car_luggage_balance_plot width="60%"}

![Number of Doors vs. Evaluation Class with Class Balance](../output/fig_relation_doors_2.png){#fig-car_doors_balance_plot width="60%"}

The "safety vs. Evaluation Class" plot @fig-car_safety_balance_plot shows that cars with high safety ratings mostly receive `vgood`/`good` evaluations, while `low`/`med` safety cars are often labeled `unacc`. In "buying vs. Evaluation Class" @fig-car_buying_balance_plot, higher prices (`high`, `vhigh`) correlate with `unacc`, while affordable cars (`low`, `med`) are more likely to be `acc`/`vgood`. The "Number of Passenger vs. Evaluation Class" @fig-car_persons_balance_plot. indicates that cars with more passenger capacity tend to be `unacc`due to impracticality. For "maint vs. Evaluation Class" @fig-car_maintenance_balance_plot, high maintenance costs link to `unacc`, while lower costs improve acceptability. Lastly, door count has a minimal impact as shown in @fig-car_doors_balance_plot, with `unacc` prevailing across categories, though cars with 5+ doors show slightly higher `acc`/`vgood`. Overall, `unacc` is associated with high-cost, low-safety, or impractical configurations, while `vgood`/`good` relate to affordability, safety, and utility.

### Correlation Heatmap

![Correlation Heatmap](../output/fig_corr_heatmap.png){#fig-corr_heatmap width="60%"}

Generates a correlation heatmap to examine relationships between features. Helps identify redundant or highly correlated features. This visualization @fig-corr_heatmap illustrates the correlation and feature importance of various factors that influence car evaluation outcomes. The values range from -1, indicating a strong negative association, to +1, which indicates a strong positive association.

The strongest predictors are safety ratings and buying prices. Higher safety ratings are strongly associated with more favorable evaluations (such as "very good" or "good"), while cars with high or very high buying prices tend to receive negative outcomes (such as "unacceptable").

Maintenance costs and the number of doors have a moderate influence, with lower maintenance costs enhancing acceptability. In contrast, features like luggage boot size and passenger capacity show minimal impact on car evaluations.

### Classification Model

1.  Splits the balanced dataset into 75% training and 25% testing sets for model training and evaluation.

2.  Trains two models:

-   `Random Forest (rf)`: Uses multiple decision trees with feature selection.

-   `Bagging (bag)`: Uses all features to grow trees, reducing variance.

3.  Predicts class labels for the test set and computes a confusion matrix to evaluate accuracy, sensitivity, and specificity of the model.


```{r}
#| label: tbl-overall_confusion_matrix
#| tbl-cap: Confusion Matrix of Random Forest Model

confusion_matrix <- readRDS("../output/matrix.RDS")
knitr::kable(confusion_matrix$overall)
knitr::kable(confusion_matrix$byClass)

accuracy <- round(confusion_matrix$overall["Accuracy"], 3)
accuracy_percentage <- accuracy*100
kappa <- round(confusion_matrix$overall["Kappa"], 3)

```

The confusion matrix summarizes the performance of the Random Forest model by showing the number of correct and incorrect predictions across different classes. It provides insights into how well the model distinguishes between categories by comparing actual vs. predicted values as shown in @tbl-overall_confusion_matrix. It also highlights the balance of correct and incorrect predictions across all classes. Per-class metrics—such as sensitivity, specificity, precision, and recall—demonstrate strong performance across both majority and minority classes, confirming that SMOTE improved recognition of previously underrepresented categories.

The Random Forest model, trained on the SMOTE-adjusted dataset and evaluated on a held-out test set, achieved an overall accuracy approximately of `{r} accuracy`, correctly classifying cars in most cases. The approximate Kappa score `{r} kappa` indicates a strong agreement between predictions and actual labels, while the high sensitivity and specificity values demonstrate excellent detection ability across all classes.

In the context of car evaluation, achieving high accuracy is significant because it suggests the model can reliably perform classification tasks that may influence consumer decision-making, regulatory assessment, or quality assurance in the automotive industry. However, not all errors carry the same weight. For instance, misclassifying an "unacceptable" car as "acceptable" (a false positive) could have serious safety or financial consequences. Therefore, in addition to accuracy, it is essential to evaluate the performance of the model on a per-class basis and ensure that it does not favor dominant classes. We addressed this risk by employing SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset. By achieving strong results across all categories, our model offers a robust and fair approach to predicting car acceptability.

### Result Visualization

We visualize the confusion matrix to get a better idea of the accuracy of the model.

```{r}
#| label: tbl-confusion_matrix_table
#| tbl-cap: Confusion Matrix of Random Forest Model

confusion_matrix <- readRDS("../output/matrix.RDS")
knitr::kable(confusion_matrix$table)
```

![Confusion Matrix Heatmap](../output/fig_conf_matrix.png){#fig-confusion_maxtrix__heatmap width="60%"}

In @fig-confusion_maxtrix__heatmap and @tbl-confusion_matrix_table, the diagonal elements represent correct classifications, which means the model accurately predicted those classes of car. The off-diagonal elements represent incorrect classifications, which shows errors in the model made. Most of the predictions fall on the diagonal line, suggesting that the model performs very well in predicting the dataset. There are few cases of misclassification, which means that the accuracy rate is high.

## Discussion

### Analysis and Evaluation

Our random forest model achieves approximate accuracy of `{r} accuracy_percentage`% and a strong Kappa statistic about `{r} kappa`, which shows it effectively predicts car acceptability base on the six measurements.

The results we got were very much in line with our expectations as our model performed very well. Our model correctly classifies almost all cars into the correct acceptable categories.

The results we get are very important for decision-making in the automotive industry. Consumers can choose to purchase vehicles based on demand, manufacturers can prioritize the demand for vehicle production, and dealers can develop strategies that are more in line with the market.

Our model is very good, but we still have some interesting questions for the future. Will additional features, such as brand, have an impact on the prediction? Is there any other model that is faster with no loss of accuracy? How is it possible to make our model more realistic? In conclusion, in the future, we may refine the data, compare more models, or try to apply our models to real-world problems.

### Limitations

1. The dataset contains a limited number of categorical features such as price and safety. Other potential influencing factors such as brand reliability, consumer ratings, etc. are not taken into account, which may reduce the prediction accuracy in practical applications.

2. While the Random Forest model performs very well, it lacks interpretability compared to simpler models such as logistic regression or decision trees.

Therefore, these are aspects that we can improve in the future.


## References
